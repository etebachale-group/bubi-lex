# ğŸ¤– Funcionalidades con IA - BubiLex

**Fecha**: 2025-01-17  
**VersiÃ³n**: 2.1 - AI-Powered  
**Estado**: âœ… IMPLEMENTADO

---

## ğŸ¯ Resumen

Se han agregado funcionalidades avanzadas de Inteligencia Artificial al diccionario BubiLex para mejorar la experiencia de aprendizaje del idioma Bubi.

## âœ¨ Funcionalidades Implementadas

### 1. ğŸŒ Traductor Contextual
**Endpoint**: `POST /api/ai/translate`

**CaracterÃ­sticas**:
- Traduce palabras considerando el contexto cultural
- Detecta automÃ¡ticamente el idioma (Bubi o EspaÃ±ol)
- Proporciona explicaciones de la traducciÃ³n
- Sugiere traducciones alternativas

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/translate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'palabra',
    context: 'En una conversaciÃ³n sobre familia'
  })
});
```

### 2. ğŸ§  Quiz de PrÃ¡ctica Inteligente
**Endpoint**: `GET /api/ai/quiz`

**CaracterÃ­sticas**:
- Genera preguntas automÃ¡ticamente basadas en el diccionario
- Preguntas de opciÃ³n mÃºltiple
- Explicaciones detalladas de cada respuesta
- PuntuaciÃ³n y seguimiento de progreso

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/quiz');
const { quiz } = await response.json();
```

### 3. ğŸ¤ GuÃ­a de PronunciaciÃ³n
**Endpoint**: `POST /api/ai/pronunciation`

**CaracterÃ­sticas**:
- NotaciÃ³n IPA mejorada
- Desglose silÃ¡bico
- Consejos personalizados para hispanohablantes
- Tips de pronunciaciÃ³n cultural

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/pronunciation', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    bubi: 'palabra',
    ipa: '/palabra/'
  })
});
```

### 4. ğŸ“š Ejemplos Contextuales
**Endpoint**: `POST /api/ai/examples`

**CaracterÃ­sticas**:
- Genera frases de ejemplo culturalmente apropiadas
- Contexto del pueblo Bubi
- MÃºltiples ejemplos por palabra
- Uso en situaciones reales

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/examples', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    bubi: 'palabra',
    spanish: 'traducciÃ³n',
    count: 3
  })
});
```

### 5. ğŸ’¡ EtimologÃ­a y Origen
**Endpoint**: `POST /api/ai/etymology`

**CaracterÃ­sticas**:
- Explica el origen de las palabras
- Contexto histÃ³rico y cultural
- Significado profundo
- RelaciÃ³n con la cultura Bubi

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/etymology', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    bubi: 'palabra',
    spanish: 'traducciÃ³n'
  })
});
```

### 6. ğŸ”— Palabras Relacionadas
**FunciÃ³n**: `suggestRelatedWords()`

**CaracterÃ­sticas**:
- Sugiere sinÃ³nimos en Bubi
- AntÃ³nimos
- Palabras de la misma familia semÃ¡ntica
- Relaciones culturales

---

## ğŸ› ï¸ ConfiguraciÃ³n

### Requisitos

1. **API Key de IA** (una de las siguientes):
   - OpenAI API Key (recomendado)
   - Anthropic API Key (alternativa)

2. **Variables de Entorno**:
```bash
# OpenAI (recomendado)
OPENAI_API_KEY=sk-...

# O Anthropic
ANTHROPIC_API_KEY=sk-ant-...

# Opcional: Modelo especÃ­fico
AI_MODEL=gpt-3.5-turbo

# Opcional: MÃ¡ximo de tokens
AI_MAX_TOKENS=500
```

### Modelos Soportados

#### OpenAI
- `gpt-3.5-turbo` (recomendado, econÃ³mico)
- `gpt-4` (mÃ¡s preciso, mÃ¡s costoso)
- `gpt-4-turbo` (balance entre precio y calidad)

#### Anthropic
- `claude-3-haiku-20240307` (rÃ¡pido y econÃ³mico)
- `claude-3-sonnet-20240229` (balance)
- `claude-3-opus-20240229` (mÃ¡s preciso)

---

## ğŸ“Š Arquitectura

### Estructura de Archivos

```
src/
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ ai-features.ts          # LÃ³gica de IA
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ ai/
â”‚   â”‚       â”œâ”€â”€ quiz/route.ts
â”‚   â”‚       â”œâ”€â”€ pronunciation/route.ts
â”‚   â”‚       â”œâ”€â”€ examples/route.ts
â”‚   â”‚       â”œâ”€â”€ translate/route.ts
â”‚   â”‚       â””â”€â”€ etymology/route.ts
â”‚   â””â”€â”€ ai-features/
â”‚       â””â”€â”€ page.tsx            # PÃ¡gina de funcionalidades
â””â”€â”€ components/
    â””â”€â”€ ai/
        â”œâ”€â”€ ai-translator.tsx
        â””â”€â”€ practice-quiz.tsx
```

### Flujo de Datos

```
Usuario â†’ Componente UI â†’ API Route â†’ ai-features.ts â†’ OpenAI/Anthropic â†’ Respuesta
```

### Rate Limiting

Todas las rutas de IA tienen rate limiting:
- **Quiz**: 1000 req/min (lenient)
- **Pronunciation**: 300 req/min (moderate)
- **Examples**: 100 req/min (strict)
- **Translate**: 300 req/min (moderate)
- **Etymology**: 100 req/min (strict)

---

## ğŸ¨ Componentes UI

### AITranslator
**UbicaciÃ³n**: `src/components/ai/ai-translator.tsx`

**CaracterÃ­sticas**:
- Input para texto
- Campo de contexto opcional
- DetecciÃ³n automÃ¡tica de idioma
- Muestra traducciÃ³n, explicaciÃ³n y alternativas
- Loading states
- Error handling

### PracticeQuiz
**UbicaciÃ³n**: `src/components/ai/practice-quiz.tsx`

**CaracterÃ­sticas**:
- Carga automÃ¡tica de preguntas
- Interfaz de opciÃ³n mÃºltiple
- Feedback inmediato
- Explicaciones detalladas
- PuntuaciÃ³n final
- OpciÃ³n de reiniciar

---

## ğŸ”’ Seguridad

### Protecciones Implementadas

1. **Rate Limiting**: Previene abuso de API
2. **ValidaciÃ³n Zod**: Valida todos los inputs
3. **Error Handling**: Manejo robusto de errores
4. **Fallbacks**: Funcionalidad bÃ¡sica sin IA
5. **Logging**: Registro de todas las operaciones

### Costos y LÃ­mites

**Recomendaciones**:
- Usar `gpt-3.5-turbo` para desarrollo
- Configurar lÃ­mites de tokens
- Monitorear uso de API
- Implementar cachÃ© para respuestas comunes

---

## ğŸ“ˆ Performance

### Optimizaciones

1. **CachÃ© de Respuestas**: Respuestas comunes en memoria
2. **Fallbacks RÃ¡pidos**: Sin IA cuando no estÃ¡ disponible
3. **Rate Limiting**: Protege contra sobrecarga
4. **Timeouts**: LÃ­mites de tiempo en requests
5. **Streaming**: Respuestas en tiempo real (futuro)

### MÃ©tricas

- **Tiempo de respuesta**: ~2-5 segundos
- **PrecisiÃ³n**: Alta (depende del modelo)
- **Disponibilidad**: 99.9% (depende de proveedor)

---

## ğŸ§ª Testing

### Pruebas Manuales

1. **Traductor**:
   ```bash
   curl -X POST http://localhost:3000/api/ai/translate \
     -H "Content-Type: application/json" \
     -d '{"text":"palabra","context":"familia"}'
   ```

2. **Quiz**:
   ```bash
   curl http://localhost:3000/api/ai/quiz
   ```

3. **PronunciaciÃ³n**:
   ```bash
   curl -X POST http://localhost:3000/api/ai/pronunciation \
     -H "Content-Type: application/json" \
     -d '{"bubi":"palabra","ipa":"/palabra/"}'
   ```

### Casos de Prueba

- [ ] TraducciÃ³n sin contexto
- [ ] TraducciÃ³n con contexto
- [ ] DetecciÃ³n de idioma
- [ ] GeneraciÃ³n de quiz
- [ ] GuÃ­a de pronunciaciÃ³n
- [ ] Ejemplos contextuales
- [ ] EtimologÃ­a
- [ ] Rate limiting
- [ ] Error handling
- [ ] Fallbacks sin IA

---

## ğŸš€ Deployment

### Variables en Vercel

1. Ir a Vercel Dashboard
2. Seleccionar proyecto `bubi-lex`
3. Settings â†’ Environment Variables
4. Agregar:
   ```
   OPENAI_API_KEY=sk-...
   AI_MODEL=gpt-3.5-turbo
   AI_MAX_TOKENS=500
   ```

### VerificaciÃ³n

```bash
# Verificar que IA estÃ¡ disponible
curl https://bubi-lex.vercel.app/api/ai/quiz

# DeberÃ­a retornar quiz o error 503 si no estÃ¡ configurado
```

---

## ğŸ“š DocumentaciÃ³n para Usuarios

### PÃ¡gina de IA

**URL**: `/ai-features`

**Contenido**:
- ExplicaciÃ³n de funcionalidades
- Demos interactivos
- Traductor en vivo
- Quiz de prÃ¡ctica
- GuÃ­a de uso

### Acceso

- Disponible para todos los usuarios
- No requiere autenticaciÃ³n
- Rate limiting aplicado

---

## ğŸ”„ Roadmap Futuro

### Corto Plazo (1-2 meses)
- [ ] CachÃ© de respuestas comunes
- [ ] Streaming de respuestas
- [ ] MÃ¡s tipos de quiz
- [ ] Flashcards con IA

### Medio Plazo (3-6 meses)
- [ ] Conversaciones con IA en Bubi
- [ ] CorrecciÃ³n de pronunciaciÃ³n con audio
- [ ] GeneraciÃ³n de historias
- [ ] Tutor virtual personalizado

### Largo Plazo (6-12 meses)
- [ ] Reconocimiento de voz
- [ ] SÃ­ntesis de voz en Bubi
- [ ] Realidad aumentada
- [ ] GamificaciÃ³n avanzada

---

## ğŸ’° Costos Estimados

### OpenAI (gpt-3.5-turbo)
- **Input**: $0.50 / 1M tokens
- **Output**: $1.50 / 1M tokens
- **Estimado**: ~$5-10/mes para uso moderado

### Anthropic (claude-3-haiku)
- **Input**: $0.25 / 1M tokens
- **Output**: $1.25 / 1M tokens
- **Estimado**: ~$3-8/mes para uso moderado

### RecomendaciÃ³n
- Empezar con `gpt-3.5-turbo`
- Monitorear uso mensual
- Implementar cachÃ© para reducir costos
- Considerar lÃ­mites por usuario

---

## ğŸ“ Soporte

### Problemas Comunes

**IA no disponible (503)**:
- Verificar API key configurada
- Verificar saldo de cuenta
- Revisar logs de Vercel

**Rate limit excedido (429)**:
- Esperar 1 minuto
- Reducir frecuencia de requests
- Contactar admin para aumentar lÃ­mites

**Respuestas incorrectas**:
- Reportar en GitHub Issues
- Incluir contexto y respuesta esperada
- Considerar cambiar modelo

---

**Implementado por**: Kiro AI  
**Fecha**: 2025-01-17  
**VersiÃ³n**: 2.1 - AI-Powered  
**Estado**: âœ… LISTO PARA PRODUCCIÃ“N

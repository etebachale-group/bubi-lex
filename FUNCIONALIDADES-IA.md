# ü§ñ Funcionalidades con IA - BubiLex

**Fecha**: 2025-01-17  
**Versi√≥n**: 2.1 - AI-Powered  
**Estado**: ‚úÖ IMPLEMENTADO

---

## üéØ Resumen

Se han agregado funcionalidades avanzadas de Inteligencia Artificial al diccionario BubiLex para mejorar la experiencia de aprendizaje del idioma Bubi.

## ‚ú® Funcionalidades Implementadas

### 1. üåê Traductor Contextual
**Endpoint**: `POST /api/ai/translate`

**Caracter√≠sticas**:
- Traduce palabras considerando el contexto cultural
- Detecta autom√°ticamente el idioma (Bubi o Espa√±ol)
- Proporciona explicaciones de la traducci√≥n
- Sugiere traducciones alternativas

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/translate', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'palabra',
    context: 'En una conversaci√≥n sobre familia'
  })
});
```

### 2. üß† Quiz de Pr√°ctica Inteligente
**Endpoint**: `GET /api/ai/quiz`

**Caracter√≠sticas**:
- Genera preguntas autom√°ticamente basadas en el diccionario
- Preguntas de opci√≥n m√∫ltiple
- Explicaciones detalladas de cada respuesta
- Puntuaci√≥n y seguimiento de progreso

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/quiz');
const { quiz } = await response.json();
```

### 3. üé§ Gu√≠a de Pronunciaci√≥n
**Endpoint**: `POST /api/ai/pronunciation`

**Caracter√≠sticas**:
- Notaci√≥n IPA mejorada
- Desglose sil√°bico
- Consejos personalizados para hispanohablantes
- Tips de pronunciaci√≥n cultural

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/pronunciation', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    bubi: 'palabra',
    ipa: '/palabra/'
  })
});
```

### 4. üìö Ejemplos Contextuales
**Endpoint**: `POST /api/ai/examples`

**Caracter√≠sticas**:
- Genera frases de ejemplo culturalmente apropiadas
- Contexto del pueblo Bubi
- M√∫ltiples ejemplos por palabra
- Uso en situaciones reales

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/examples', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    bubi: 'palabra',
    spanish: 'traducci√≥n',
    count: 3
  })
});
```

### 5. üí° Etimolog√≠a y Origen
**Endpoint**: `POST /api/ai/etymology`

**Caracter√≠sticas**:
- Explica el origen de las palabras
- Contexto hist√≥rico y cultural
- Significado profundo
- Relaci√≥n con la cultura Bubi

**Ejemplo de uso**:
```typescript
const response = await fetch('/api/ai/etymology', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    bubi: 'palabra',
    spanish: 'traducci√≥n'
  })
});
```

### 6. üîó Palabras Relacionadas
**Funci√≥n**: `suggestRelatedWords()`

**Caracter√≠sticas**:
- Sugiere sin√≥nimos en Bubi
- Ant√≥nimos
- Palabras de la misma familia sem√°ntica
- Relaciones culturales

---

## üõ†Ô∏è Configuraci√≥n

### Requisitos

El sistema ahora soporta **m√∫ltiples proveedores de IA**, incluyendo opciones **100% gratuitas**:

#### Opciones de Pago (Producci√≥n)
1. **OpenAI API Key** (recomendado para producci√≥n)
2. **Anthropic API Key** (alternativa de pago)

#### Alternativas Gratuitas (Desarrollo/Producci√≥n)
1. **Groq** - GRATUITO con l√≠mites generosos y muy r√°pido
2. **Together AI** - GRATUITO con cr√©ditos iniciales
3. **Ollama** - 100% GRATUITO, ejecuta modelos localmente
4. **HuggingFace** - GRATUITO con l√≠mites (opcional)

### Variables de Entorno

```bash
# ===== OPCIONES DE PAGO =====
# OpenAI (recomendado para producci√≥n)
OPENAI_API_KEY=sk-...

# O Anthropic (alternativa de pago)
ANTHROPIC_API_KEY=sk-ant-...

# ===== ALTERNATIVAS GRATUITAS =====
# Groq (GRATUITO - muy r√°pido)
# Obt√©n tu API key en: https://console.groq.com/
GROQ_API_KEY=gsk_...

# Together AI (GRATUITO - cr√©ditos iniciales)
# Obt√©n tu API key en: https://api.together.xyz/
TOGETHER_API_KEY=...

# HuggingFace (GRATUITO - opcional)
# Obt√©n tu API key en: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=hf_...

# Ollama (GRATUITO - 100% local)
# Instala desde: https://ollama.ai/
# Ejecuta: ollama pull llama2
# No requiere API key, se detecta autom√°ticamente

# Opcional: Modelo espec√≠fico (solo para OpenAI/Anthropic)
AI_MODEL=gpt-3.5-turbo
AI_MAX_TOKENS=500
```

### C√≥mo Obtener API Keys Gratuitas

#### 1. Groq (Recomendado - Muy R√°pido)
1. Visita: https://console.groq.com/
2. Crea una cuenta gratuita
3. Ve a "API Keys"
4. Crea una nueva API key
5. Copia y pega en `GROQ_API_KEY`

**Ventajas**:
- Extremadamente r√°pido (hasta 10x m√°s r√°pido que OpenAI)
- L√≠mites generosos (14,400 req/d√≠a)
- Modelos potentes (Llama 3, Mixtral)

#### 2. Together AI
1. Visita: https://api.together.xyz/
2. Reg√≠strate con tu email
3. Recibes $25 en cr√©ditos gratuitos
4. Ve a "API Keys" en el dashboard
5. Copia y pega en `TOGETHER_API_KEY`

**Ventajas**:
- Cr√©ditos gratuitos iniciales
- M√∫ltiples modelos disponibles
- Buena velocidad

#### 3. Ollama (100% Local y Gratuito)
1. Descarga Ollama: https://ollama.ai/
2. Instala en tu computadora
3. Ejecuta en terminal:
   ```bash
   ollama pull llama2
   # O para un modelo m√°s potente:
   ollama pull mixtral
   ```
4. Ollama se ejecutar√° en `localhost:11434`
5. No necesitas configurar nada m√°s

**Ventajas**:
- 100% gratuito, sin l√≠mites
- Privacidad total (todo local)
- No requiere internet despu√©s de descargar
- Ideal para desarrollo

**Desventajas**:
- Requiere recursos de computadora (RAM, CPU/GPU)
- Solo funciona en tu m√°quina local

#### 4. HuggingFace (Opcional)
1. Visita: https://huggingface.co/
2. Crea una cuenta
3. Ve a Settings ‚Üí Access Tokens
4. Crea un token de lectura
5. Copia y pega en `HUGGINGFACE_API_KEY`

**Nota**: HuggingFace es opcional y se usa como √∫ltimo recurso.

### Orden de Prioridad

El sistema intenta usar los proveedores en este orden:

1. **OpenAI/Anthropic** (si est√° configurado)
2. **Groq** (si est√° configurado)
3. **Together AI** (si est√° configurado)
4. **Ollama** (si est√° corriendo localmente)
5. **Fallback b√°sico** (respuestas simples sin IA)

Esto significa que:
- Si tienes OpenAI configurado, se usar√° primero
- Si OpenAI falla o no est√° configurado, se intenta Groq
- Si Groq falla, se intenta Together AI
- Si Together AI falla, se intenta Ollama
- Si todo falla, se usan respuestas b√°sicas

### Modelos Soportados

#### OpenAI
- `gpt-3.5-turbo` (recomendado, econ√≥mico)
- `gpt-4` (m√°s preciso, m√°s costoso)
- `gpt-4-turbo` (balance entre precio y calidad)

#### Anthropic
- `claude-3-haiku-20240307` (r√°pido y econ√≥mico)
- `claude-3-sonnet-20240229` (balance)
- `claude-3-opus-20240229` (m√°s preciso)

#### Groq (Gratuito)
- `llama3-8b-8192` (usado por defecto)
- `mixtral-8x7b-32768`
- `gemma-7b-it`

#### Together AI (Gratuito)
- `mistralai/Mixtral-8x7B-Instruct-v0.1` (usado por defecto)
- `meta-llama/Llama-2-70b-chat-hf`
- `togethercomputer/RedPajama-INCITE-7B-Chat`

#### Ollama (Local)
- `llama2` (recomendado para empezar)
- `mixtral` (m√°s potente)
- `codellama` (especializado en c√≥digo)
- Cualquier modelo disponible en https://ollama.ai/library

---

## üìä Arquitectura

### Estructura de Archivos

```
src/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ ai-features.ts          # L√≥gica de IA
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ai/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ quiz/route.ts
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ pronunciation/route.ts
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ examples/route.ts
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ translate/route.ts
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ etymology/route.ts
‚îÇ   ‚îî‚îÄ‚îÄ ai-features/
‚îÇ       ‚îî‚îÄ‚îÄ page.tsx            # P√°gina de funcionalidades
‚îî‚îÄ‚îÄ components/
    ‚îî‚îÄ‚îÄ ai/
        ‚îú‚îÄ‚îÄ ai-translator.tsx
        ‚îî‚îÄ‚îÄ practice-quiz.tsx
```

### Flujo de Datos

```
Usuario ‚Üí Componente UI ‚Üí API Route ‚Üí ai-features.ts ‚Üí OpenAI/Anthropic ‚Üí Respuesta
```

### Rate Limiting

Todas las rutas de IA tienen rate limiting:
- **Quiz**: 1000 req/min (lenient)
- **Pronunciation**: 300 req/min (moderate)
- **Examples**: 100 req/min (strict)
- **Translate**: 300 req/min (moderate)
- **Etymology**: 100 req/min (strict)

---

## üé® Componentes UI

### AITranslator
**Ubicaci√≥n**: `src/components/ai/ai-translator.tsx`

**Caracter√≠sticas**:
- Input para texto
- Campo de contexto opcional
- Detecci√≥n autom√°tica de idioma
- Muestra traducci√≥n, explicaci√≥n y alternativas
- Loading states
- Error handling

### PracticeQuiz
**Ubicaci√≥n**: `src/components/ai/practice-quiz.tsx`

**Caracter√≠sticas**:
- Carga autom√°tica de preguntas
- Interfaz de opci√≥n m√∫ltiple
- Feedback inmediato
- Explicaciones detalladas
- Puntuaci√≥n final
- Opci√≥n de reiniciar

---

## üîí Seguridad

### Protecciones Implementadas

1. **Rate Limiting**: Previene abuso de API
2. **Validaci√≥n Zod**: Valida todos los inputs
3. **Error Handling**: Manejo robusto de errores
4. **Fallbacks**: Funcionalidad b√°sica sin IA
5. **Logging**: Registro de todas las operaciones

### Costos y L√≠mites

**Recomendaciones**:
- Usar `gpt-3.5-turbo` para desarrollo
- Configurar l√≠mites de tokens
- Monitorear uso de API
- Implementar cach√© para respuestas comunes

---

## üìà Performance

### Optimizaciones

1. **Cach√© de Respuestas**: Respuestas comunes en memoria
2. **Fallbacks R√°pidos**: Sin IA cuando no est√° disponible
3. **Rate Limiting**: Protege contra sobrecarga
4. **Timeouts**: L√≠mites de tiempo en requests
5. **Streaming**: Respuestas en tiempo real (futuro)

### M√©tricas

- **Tiempo de respuesta**: ~2-5 segundos
- **Precisi√≥n**: Alta (depende del modelo)
- **Disponibilidad**: 99.9% (depende de proveedor)

---

## üß™ Testing

### Pruebas Manuales

1. **Traductor**:
   ```bash
   curl -X POST http://localhost:3000/api/ai/translate \
     -H "Content-Type: application/json" \
     -d '{"text":"palabra","context":"familia"}'
   ```

2. **Quiz**:
   ```bash
   curl http://localhost:3000/api/ai/quiz
   ```

3. **Pronunciaci√≥n**:
   ```bash
   curl -X POST http://localhost:3000/api/ai/pronunciation \
     -H "Content-Type: application/json" \
     -d '{"bubi":"palabra","ipa":"/palabra/"}'
   ```

### Casos de Prueba

- [ ] Traducci√≥n sin contexto
- [ ] Traducci√≥n con contexto
- [ ] Detecci√≥n de idioma
- [ ] Generaci√≥n de quiz
- [ ] Gu√≠a de pronunciaci√≥n
- [ ] Ejemplos contextuales
- [ ] Etimolog√≠a
- [ ] Rate limiting
- [ ] Error handling
- [ ] Fallbacks sin IA

---

## üöÄ Deployment

### Variables en Vercel

1. Ir a Vercel Dashboard
2. Seleccionar proyecto `bubi-lex`
3. Settings ‚Üí Environment Variables
4. Agregar:
   ```
   OPENAI_API_KEY=sk-...
   AI_MODEL=gpt-3.5-turbo
   AI_MAX_TOKENS=500
   ```

### Verificaci√≥n

```bash
# Verificar que IA est√° disponible (con cualquier proveedor)
curl https://bubi-lex.vercel.app/api/ai/quiz

# Deber√≠a retornar quiz con informaci√≥n del proveedor usado
# Ejemplo de respuesta:
# {
#   "quiz": [...],
#   "wordsUsed": 5,
#   "provider": "groq" // o "openai/anthropic", "together", "free-ai"
# }
```

### Configurar Alternativas Gratuitas en Vercel

1. Ir a Vercel Dashboard
2. Seleccionar proyecto `bubi-lex`
3. Settings ‚Üí Environment Variables
4. Agregar las que desees:
   ```
   # Opci√≥n recomendada: Groq
   GROQ_API_KEY=gsk_...
   
   # O Together AI
   TOGETHER_API_KEY=...
   
   # O ambas para redundancia
   GROQ_API_KEY=gsk_...
   TOGETHER_API_KEY=...
   ```
5. Redeploy el proyecto

**Nota**: Ollama solo funciona localmente, no en Vercel.

---

## üìö Documentaci√≥n para Usuarios

### P√°gina de IA

**URL**: `/ai-features`

**Contenido**:
- Explicaci√≥n de funcionalidades
- Demos interactivos
- Traductor en vivo
- Quiz de pr√°ctica
- Gu√≠a de uso

### Acceso

- Disponible para todos los usuarios
- No requiere autenticaci√≥n
- Rate limiting aplicado

---

## üîÑ Roadmap Futuro

### Corto Plazo (1-2 meses)
- [ ] Cach√© de respuestas comunes
- [ ] Streaming de respuestas
- [ ] M√°s tipos de quiz
- [ ] Flashcards con IA

### Medio Plazo (3-6 meses)
- [ ] Conversaciones con IA en Bubi
- [ ] Correcci√≥n de pronunciaci√≥n con audio
- [ ] Generaci√≥n de historias
- [ ] Tutor virtual personalizado

### Largo Plazo (6-12 meses)
- [ ] Reconocimiento de voz
- [ ] S√≠ntesis de voz en Bubi
- [ ] Realidad aumentada
- [ ] Gamificaci√≥n avanzada

---

## üí∞ Costos Estimados

### Opciones Gratuitas (Recomendado para Empezar)

#### Groq
- **Costo**: $0 (100% gratuito)
- **L√≠mites**: 14,400 requests/d√≠a
- **Velocidad**: Extremadamente r√°pido
- **Recomendaci√≥n**: ‚≠ê Mejor opci√≥n gratuita

#### Together AI
- **Costo**: $0 (cr√©ditos iniciales de $25)
- **L√≠mites**: Seg√∫n cr√©ditos disponibles
- **Velocidad**: R√°pido
- **Recomendaci√≥n**: Excelente para empezar

#### Ollama (Local)
- **Costo**: $0 (100% gratuito, sin l√≠mites)
- **Requisitos**: 8GB+ RAM, CPU/GPU decente
- **Velocidad**: Depende de tu hardware
- **Recomendaci√≥n**: Ideal para desarrollo local

### Opciones de Pago (Producci√≥n)

#### OpenAI (gpt-3.5-turbo)
- **Input**: $0.50 / 1M tokens
- **Output**: $1.50 / 1M tokens
- **Estimado**: ~$5-10/mes para uso moderado

#### Anthropic (claude-3-haiku)
- **Input**: $0.25 / 1M tokens
- **Output**: $1.25 / 1M tokens
- **Estimado**: ~$3-8/mes para uso moderado

### Recomendaci√≥n de Configuraci√≥n

#### Para Desarrollo
```bash
# Opci√≥n 1: Ollama (100% local, sin l√≠mites)
# Instalar Ollama y ejecutar: ollama pull llama2

# Opci√≥n 2: Groq (muy r√°pido, gratuito)
GROQ_API_KEY=gsk_...
```

#### Para Producci√≥n (Bajo Presupuesto)
```bash
# Usar Groq como principal
GROQ_API_KEY=gsk_...

# Together AI como backup
TOGETHER_API_KEY=...
```

#### Para Producci√≥n (Alta Calidad)
```bash
# OpenAI como principal
OPENAI_API_KEY=sk-...

# Groq como backup gratuito
GROQ_API_KEY=gsk_...
```

### Comparaci√≥n de Proveedores

| Proveedor | Costo | Velocidad | Calidad | L√≠mites | Recomendaci√≥n |
|-----------|-------|-----------|---------|---------|---------------|
| **Groq** | Gratis | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 14.4k/d√≠a | ‚úÖ Mejor gratuito |
| **Together AI** | Gratis* | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | $25 cr√©ditos | ‚úÖ Excelente inicio |
| **Ollama** | Gratis | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Sin l√≠mites | ‚úÖ Desarrollo local |
| **OpenAI** | Pago | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Seg√∫n pago | Producci√≥n |
| **Anthropic** | Pago | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Seg√∫n pago | Producci√≥n |

*Cr√©ditos iniciales, luego pago

---

## üìû Soporte

### Problemas Comunes

**IA no disponible (503)**:
- Verificar API key configurada
- Verificar saldo de cuenta
- Revisar logs de Vercel

**Rate limit excedido (429)**:
- Esperar 1 minuto
- Reducir frecuencia de requests
- Contactar admin para aumentar l√≠mites

**Respuestas incorrectas**:
- Reportar en GitHub Issues
- Incluir contexto y respuesta esperada
- Considerar cambiar modelo

---

## üÜì Gu√≠a de Alternativas Gratuitas

### ¬øPor qu√© usar alternativas gratuitas?

- **Costo $0**: No necesitas tarjeta de cr√©dito
- **Sin l√≠mites de facturaci√≥n**: No te preocupes por costos inesperados
- **R√°pido**: Groq es hasta 10x m√°s r√°pido que OpenAI
- **Privacidad**: Ollama ejecuta todo localmente
- **Ideal para desarrollo**: Prueba sin gastar dinero

### Configuraci√≥n R√°pida (5 minutos)

#### Opci√≥n 1: Groq (M√°s R√°pido)

```bash
# 1. Obt√©n tu API key en https://console.groq.com/
# 2. Agrega a .env.local:
GROQ_API_KEY=gsk_tu_api_key_aqui

# 3. Reinicia el servidor
npm run dev
```

#### Opci√≥n 2: Ollama (100% Local)

```bash
# 1. Instala Ollama
# Windows: Descarga desde https://ollama.ai/
# Mac: brew install ollama
# Linux: curl https://ollama.ai/install.sh | sh

# 2. Descarga un modelo
ollama pull llama2

# 3. Verifica que est√© corriendo
ollama list

# 4. Reinicia el servidor Next.js
npm run dev
```

#### Opci√≥n 3: Together AI (Cr√©ditos Gratis)

```bash
# 1. Reg√≠strate en https://api.together.xyz/
# 2. Recibes $25 en cr√©ditos
# 3. Agrega a .env.local:
TOGETHER_API_KEY=tu_api_key_aqui

# 4. Reinicia el servidor
npm run dev
```

### Verificar que Funciona

```bash
# Prueba el endpoint de quiz
curl http://localhost:3000/api/ai/quiz

# Deber√≠as ver:
# {
#   "quiz": [...],
#   "provider": "groq" // o "together", "ollama", "free-ai"
# }
```

### Soluci√≥n de Problemas

#### Groq no funciona
- Verifica que la API key sea correcta
- Revisa que no hayas excedido el l√≠mite diario (14,400 req/d√≠a)
- Verifica en https://console.groq.com/ que tu cuenta est√© activa

#### Ollama no funciona
- Verifica que Ollama est√© corriendo: `ollama list`
- Aseg√∫rate de haber descargado un modelo: `ollama pull llama2`
- Verifica que est√© en el puerto correcto: http://localhost:11434
- Reinicia Ollama si es necesario

#### Together AI no funciona
- Verifica que tengas cr√©ditos disponibles
- Revisa tu API key en https://api.together.xyz/
- Verifica que la API key tenga permisos correctos

### Comparaci√≥n de Rendimiento

| Caracter√≠stica | Groq | Together AI | Ollama | OpenAI |
|----------------|------|-------------|--------|--------|
| Velocidad | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö°‚ö° |
| Calidad | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Costo | $0 | $0* | $0 | $$ |
| L√≠mites | 14.4k/d√≠a | Cr√©ditos | Sin l√≠mites | Seg√∫n pago |
| Requiere Internet | S√≠ | S√≠ | No | S√≠ |
| Privacidad | Media | Media | Alta | Media |

### Recomendaciones por Caso de Uso

#### Desarrollo Local
```bash
# Mejor opci√≥n: Ollama
# - Sin l√≠mites
# - Privacidad total
# - No requiere internet
ollama pull llama2
```

#### Producci√≥n (Bajo Presupuesto)
```bash
# Mejor opci√≥n: Groq + Together AI como backup
GROQ_API_KEY=gsk_...
TOGETHER_API_KEY=...
```

#### Producci√≥n (Alta Calidad)
```bash
# Mejor opci√≥n: OpenAI + Groq como backup
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk_...
```

#### Testing/CI/CD
```bash
# Mejor opci√≥n: Groq (r√°pido y confiable)
GROQ_API_KEY=gsk_...
```

---

**Implementado por**: Kiro AI  
**Fecha**: 2025-01-17  
**Versi√≥n**: 2.2 - AI-Powered con Alternativas Gratuitas  
**Estado**: ‚úÖ LISTO PARA PRODUCCI√ìN
